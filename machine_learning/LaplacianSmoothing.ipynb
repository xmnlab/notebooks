{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Laplacian-Smoothing\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Laplacian Smoothing</a></div><div class=\"lev2\"><a href=\"#Test---Query-Perfect-Storm\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Test - Query Perfect Storm</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplacian Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pprint\n",
    "\n",
    "import bow\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def laplacian_smoothing(\n",
    "    v1: int, v2: int, k: int, k_class: int\n",
    "):\n",
    "    return (v1+k)/(v2+k*k_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text: str):\n",
    "    return [\n",
    "        word.strip(string.punctuation) for word in text.upper().split()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def p_query(\n",
    "    query: list, \n",
    "    domain: bow.BagOfWords,\n",
    "    bag: bow.BagOfWords,\n",
    "):\n",
    "    return [\n",
    "        laplacian_smoothing(\n",
    "            v1=domain[word] if word in domain else 0, \n",
    "            v2=sum(domain.values()), \n",
    "            k=1,\n",
    "            k_class=len(bag)  # movie and song\n",
    "        ) for word in query\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Query Perfect Storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_movie = \"\"\"\n",
    "A PERFECT WORLD\n",
    "MY PERFECT WOMAN\n",
    "PRETTY WOMAN\n",
    "\"\"\"\n",
    "\n",
    "s_song = \"\"\"\n",
    "A PERFECT DAY\n",
    "ELECTRIC STORM\n",
    "ANOTHER RAIN DAY\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DICTIONARIES\n",
      "\n",
      "movies:\n",
      "\"{'MY': 1, 'PERFECT': 2, 'WORLD': 1, 'A': 1, 'WOMAN': 2, 'PRETTY': 1}\"\n",
      "\n",
      "songs:\n",
      "(\"{'RAIN': 1, 'PERFECT': 1, 'A': 1, 'STORM': 1, 'DAY': 2, 'ELECTRIC': 1, \"\n",
      " \"'ANOTHER': 1}\")\n",
      "\n",
      "all:\n",
      "(\"{'MY': 1, 'PERFECT': 3, 'DAY': 2, 'ELECTRIC': 1, 'WORLD': 1, 'A': 2, 'RAIN': \"\n",
      " \"1, 'STORM': 1, 'WOMAN': 2, 'ANOTHER': 1, 'PRETTY': 1}\")\n"
     ]
    }
   ],
   "source": [
    "movie = bow.BagOfWords(tokenize(s_movie))\n",
    "song = bow.BagOfWords(tokenize(s_song))\n",
    "bag = movie + song\n",
    "\n",
    "print('\\nDICTIONARIES')\n",
    "print('\\nmovies:')\n",
    "pprint.pprint(str(movie))\n",
    "print('\\nsongs:')\n",
    "pprint.pprint(str(song))\n",
    "print('\\nall:')\n",
    "pprint.pprint(str(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DICTIONARIES\n",
      "movie entries: 3 | song entries: 3\n"
     ]
    }
   ],
   "source": [
    "print('\\nDICTIONARIES')\n",
    "n_movie = s_movie.count('\\n') - 1\n",
    "n_song = s_song.count('\\n') - 1\n",
    "print('movie entries:', n_movie, '| song entries:',  n_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(MOVIE):  0.5 | P(SONG): 0.5\n"
     ]
    }
   ],
   "source": [
    "p_movie = laplacian_smoothing(\n",
    "    v1=n_movie, \n",
    "    v2=n_movie+n_song, \n",
    "    k=1,\n",
    "    k_class=2  # movie and song\n",
    ")\n",
    "\n",
    "p_song = laplacian_smoothing(\n",
    "    v1=n_song, \n",
    "    v2=n_movie+n_song, \n",
    "    k=1,\n",
    "    k_class=2  # movie and song\n",
    ")\n",
    "\n",
    "print('P(MOVIE): ', p_movie, '| P(SONG):', p_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: [['PERFECT'], ['STORM']]\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    tokenize('Perfect'),\n",
    "    tokenize('Storm')\n",
    "]\n",
    "print('query:', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  ['PERFECT']\n",
      "P(PERFECT|MOVIE) 0.157894736842\n",
      "P(PERFECT|SONG) 0.105263157895\n",
      "P(MOVIE|PERFECT): 0.6\n",
      "P(SONG|PERFECT): 0.4\n",
      "\n",
      "Query:  ['STORM']\n",
      "P(STORM|MOVIE) 0.0526315789474\n",
      "P(STORM|SONG) 0.105263157895\n",
      "P(MOVIE|STORM): 0.333333333333\n",
      "P(SONG|STORM): 0.666666666667\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print('\\nQuery: ', query)\n",
    "    \n",
    "    p_q_movie = np.prod(p_query(query, movie, bag))\n",
    "    p_q_song = np.prod(p_query(query, song, bag))\n",
    "    \n",
    "    print('P(%s|MOVIE)' % ','.join(query), p_q_movie)\n",
    "    print('P(%s|SONG)' % ','.join(query), p_q_song)\n",
    "\n",
    "    p_movie_q = p_q_movie*p_movie / (p_q_movie*p_movie + p_q_song*p_song)\n",
    "    p_song_q = p_q_song*p_song / (p_q_movie*p_movie + p_q_song*p_song)\n",
    "\n",
    "    print('P(MOVIE|%s):' % ','.join(query), p_movie_q)\n",
    "    print('P(SONG|%s):' % ','.join(query), p_song_q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
